{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TGS_Salt_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z41J98mYROot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30322074-546a-48fb-f3a7-5db93e9a227b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from random import randint\n",
        "import os\n",
        "from keras import backend as K\n",
        "from metrics import dice_coef\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "import seaborn as sns\n",
        "sns.set_style(\"white\")\n",
        "from helpers import create_data_set_from_generator, get_train_generator\n",
        "from losers import dice_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from util import join_paths\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "# from keras.preprocessing.image import load_img\n",
        "# from keras import Model\n",
        "# #from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
        "# from keras.models import load_model\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from keras.optimizers import Adam\n",
        "# from keras.utils.vis_utils import plot_model\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
        "\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhnEyqPLRfXQ",
        "colab_type": "code",
        "outputId": "bad1cbbe-9ebe-4a1c-a454-808f47c60389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrzuuE95jzxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from util import join_paths\n",
        "\n",
        "def get_train_generator(directory, mask_dir, img_dir, read_type=cv2.IMREAD_GRAYSCALE):\n",
        "    def train_generator():\n",
        "        _img_dir = join_paths(directory, img_dir)\n",
        "        _mask_dir = join_paths(directory, mask_dir)\n",
        "\n",
        "        for imag_file in os.listdir(_img_dir):\n",
        "            x_img = cv2.imread(join_paths(_img_dir, imag_file), read_type)\n",
        "            y_img = cv2.imread(join_paths(_mask_dir, imag_file), read_type)\n",
        "            x_img = np.pad(x_img, ((13, 14), (13, 14)), mode='symmetric').astype(np.float64) / 255.0\n",
        "            y_img = np.pad(y_img, ((13, 14), (13, 14)), mode='symmetric').astype(np.float64) / 255.0\n",
        "            img_shape = (x_img.shape[0], x_img.shape[1], 1)\n",
        "            yield (x_img.reshape(img_shape), y_img.reshape(img_shape))\n",
        "\n",
        "    return train_generator\n",
        "\n",
        "\n",
        "def get_test_generator(directory, img_dir, read_type=cv2.IMREAD_GRAYSCALE):\n",
        "    def test_generator():\n",
        "        _img_dir = join_paths(directory, img_dir)\n",
        "        for imag_file in os.listdir(_img_dir):\n",
        "            x_img = cv2.imread(join_paths(_img_dir, imag_file), read_type)\n",
        "            yield x_img\n",
        "\n",
        "    return test_generator\n",
        "\n",
        "\n",
        "def create_data_set_from_generator(generator, _types, _shapes, buffer_size=100):\n",
        "    ds = tf.data.Dataset.from_generator(generator, _types, _shapes)\n",
        "    ds = ds.prefetch(buffer_size)\n",
        "    return ds\n",
        "\n",
        "\n",
        "def get_channels(_type):\n",
        "    if _type == cv2.IMREAD_GRAYSCALE:\n",
        "        return 1\n",
        "    elif _type == cv2.IMREAD_COLOR:\n",
        "        return 3\n",
        "    return 1\n",
        "\n",
        "\n",
        "def create_tfrecord(image_mask_list: [()], tfrecord_file, preprocess_callbacks: [callable] = None,\n",
        "                    _type=cv2.IMREAD_GRAYSCALE):\n",
        "    with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
        "        for img_file, mask_file in image_mask_list:\n",
        "            ser_img = serialize_tgs_image(img_file, mask_file, preprocess_callbacks, _type)\n",
        "            writer.write(ser_img.SerializeToString())\n",
        "\n",
        "\n",
        "def pad_images(img, mask, pad_shapes=((13, 14), (13, 14))):\n",
        "    img = np.pad(img, pad_shapes, mode='symmetric').astype(np.float32) / 255.0\n",
        "    mask = np.pad(mask, pad_shapes, mode='symmetric').astype(np.float32) / 255.0\n",
        "    return img, mask\n",
        "\n",
        "\n",
        "def reshape_img(img, mask, shape=(128, 128, 1)):\n",
        "    img = np.resize(img, shape)\n",
        "    mask = np.resize(mask, shape)\n",
        "    return img, mask\n",
        "\n",
        "\n",
        "def serialize_tgs_image(img_file, mask_file, preprocess_callbacks: [callable], _type):\n",
        "    img = cv2.imread(img_file, _type)\n",
        "    mask = cv2.imread(mask_file, _type)\n",
        "    if preprocess_callbacks:\n",
        "        for preprocess_callback in preprocess_callbacks:\n",
        "            img, mask = preprocess_callback(img, mask)\n",
        "\n",
        "    img = img.astype(np.float32)\n",
        "    mask = mask.astype(np.float32)\n",
        "\n",
        "    ser_image = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'img': tf.train.Feature(float_list=tf.train.FloatList(value=img.reshape(-1).tolist())),\n",
        "        'mask': tf.train.Feature(float_list=tf.train.FloatList(value=mask.reshape(-1).tolist()))\n",
        "    }))\n",
        "    return ser_image\n",
        "\n",
        "\n",
        "def get_train_val_paths(directory, imgs_dir, masks_dir, percentage=0.8):\n",
        "    _img_dir = join_paths(directory, imgs_dir)\n",
        "    _mask_dir = join_paths(directory, masks_dir)\n",
        "    images = [(join_paths(_img_dir, img_file), join_paths(_mask_dir, img_file)) for img_file in os.listdir(_img_dir)]\n",
        "    train_size = int(percentage * len(images))\n",
        "    return images[:train_size], images[train_size:]\n",
        "\n",
        "\n",
        "def create_deserializer(shape=(128, 128, 1)):\n",
        "    def deserialize_tgs_image(tfrecord):\n",
        "        features = {\n",
        "            'img': tf.FixedLenFeature(shape, tf.float32),\n",
        "            'mask': tf.FixedLenFeature(shape, tf.float32)\n",
        "        }\n",
        "        sample = tf.parse_single_example(tfrecord, features)\n",
        "        img = sample['img']\n",
        "        mask = sample['mask']\n",
        "        return tf.cast(img, tf.float64), tf.cast(mask, tf.float64)\n",
        "    return deserialize_tgs_image\n",
        "\n",
        "\n",
        "def create_dataset_from_tfrecord(tf_records, decode_func):\n",
        "    dataset = tf.data.TFRecordDataset(tf_records)\n",
        "    dataset = dataset.map(decode_func)\n",
        "    dataset = dataset.prefetch(64)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "    # train_ds = create_dataset_from_tfrecord(['train_images.tfrecord'], create_deserializer())\n",
        "    # start_time = time.time()\n",
        "    # for batch in train_ds.take(3200):\n",
        "    #     cv2.imshow('img', (batch[0].numpy() * 255.0).astype(np.uint8))\n",
        "    #     cv2.imshow('mask', (batch[1].numpy() * 255.0).astype(np.uint8))\n",
        "    #     cv2.waitKey()\n",
        "    # print('time elapsed {}'.format(time.time() - start_time))\n",
        "    #\n",
        "    # ds_train = create_data_set_from_generator(get_train_generator('./tgs/train', mask_dir='masks', img_dir='images'),\n",
        "    #                                           _types=(tf.float64, tf.float64),\n",
        "    #                                           _shapes=(tf.TensorShape([128, 128, 1]), tf.TensorShape([128, 128, 1])))\n",
        "    # start_time = time.time()\n",
        "    # for batch in ds_train.take(3200):\n",
        "    #     print('.', end='')\n",
        "    # print('')\n",
        "    # print('time elapsed {}', format(time.time()-start_time))\n",
        "# train_files, validation_files = get_train_val_paths('drive/My Drive/Colab Notebooks/train', masks_dir='masks', imgs_dir='images')\n",
        "# print(len(train_files))\n",
        "# print(len(validation_files))\n",
        "# create_tfrecord(train_files, 'train_images.tfrecord', [reshape_img])\n",
        "# create_tfrecord(validation_files, 'validation_images.tfrecord', [reshape_img])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw3zFAtWkCUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = create_dataset_from_tfrecord(['train_images.tfrecord'], create_deserializer())\n",
        "valid_ds = create_dataset_from_tfrecord(['validation_images.tfrecord'], create_deserializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvsXNVMGR4aw",
        "colab_type": "text"
      },
      "source": [
        "# Layers#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E6hFaNlR5gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UnetEncodeLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, kernel_size, filters, pool_size=(2, 2), dropout_value=0.25):\n",
        "        super(UnetEncodeLayer, self).__init__()\n",
        "\n",
        "        self.dropout_value = dropout_value\n",
        "        self.layer1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')\n",
        "        self.layer2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size)\n",
        "        self.dropout = tf.keras.layers.Dropout(self.dropout_value)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        _out = self.layer1(inputs)\n",
        "        _out = self.layer2(_out)\n",
        "        _out_pool = self.pool(_out)\n",
        "\n",
        "        return _out, self.dropout(_out_pool)\n",
        "\n",
        "\n",
        "class UnetDecodeLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, kernel_size, filters, dropout_value=0.25, strides=(2, 2)):\n",
        "        super(UnetDecodeLayer, self).__init__()\n",
        "\n",
        "        self.deconv_layer = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=kernel_size, padding='same', strides=strides)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_value) if dropout_value is not None else None\n",
        "        self.layer1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu')\n",
        "        self.layer2 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu')\n",
        "\n",
        "    def call(self, inputs, concat_layer):\n",
        "        _out = self.deconv_layer(inputs)\n",
        "        _out = tf.keras.layers.concatenate([concat_layer, _out])\n",
        "        _out = self.dropout(_out)\n",
        "        _out = self.layer1(_out)\n",
        "        return self.layer2(_out)\n",
        "\n",
        "\n",
        "class UnetMiddleLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, kernel_size, filters):\n",
        "        super(UnetMiddleLayer, self).__init__()\n",
        "        self.layer1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')\n",
        "        self.layer2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        _out = self.layer1(inputs)\n",
        "        return self.layer2(_out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s1sE9rOSr9U",
        "colab_type": "text"
      },
      "source": [
        "# Set generators\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGrAbjmVR9IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_generator(directory, mask_dir, img_dir, read_type=cv2.IMREAD_GRAYSCALE):\n",
        "    def train_generator():\n",
        "        _img_dir = join_paths(directory, img_dir)\n",
        "        _mask_dir = join_paths(directory, mask_dir)\n",
        "\n",
        "        for imag_file in os.listdir(_img_dir):\n",
        "            x_img = cv2.imread(join_paths(_img_dir, imag_file), read_type)\n",
        "            y_img = cv2.imread(join_paths(_mask_dir, imag_file), read_type)\n",
        "            x_img = np.pad(x_img, ((13, 14), (13, 14)), mode='symmetric').astype(np.float64) / 255.0\n",
        "            y_img = np.pad(y_img, ((13, 14), (13, 14)), mode='symmetric').astype(np.float64) / 255.0\n",
        "            img_shape = (x_img.shape[0], x_img.shape[1], 1)\n",
        "            yield (x_img.reshape(img_shape), y_img.reshape(img_shape))\n",
        "\n",
        "    return train_generator\n",
        "\n",
        "\n",
        "def get_test_generator(directory, img_dir, read_type=cv2.IMREAD_GRAYSCALE):\n",
        "    def test_generator():\n",
        "        _img_dir = join_paths(directory, img_dir)\n",
        "        for imag_file in os.listdir(_img_dir):\n",
        "            x_img = cv2.imread(join_paths(_img_dir, imag_file), read_type)\n",
        "            yield x_img\n",
        "\n",
        "    return test_generator\n",
        "\n",
        "\n",
        "def create_data_set_from_generator(generator, _types, _shapes, buffer_size=100):\n",
        "    ds = tf.data.Dataset.from_generator(generator, _types, _shapes)\n",
        "    ds = ds.prefetch(buffer_size)\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvoGf_E2G29N",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5U8IMSfSqek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UnetModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(UnetModel, self).__init__()\n",
        "        kernel_shape = (3, 3)\n",
        "        filters = 64\n",
        "        # block1 encoder\n",
        "        # input_shape = input_shape; ex. (128, 128)\n",
        "        # output_shape = (input_shape) / 2; ex. (64, 64, filters)\n",
        "        self.block1_encoder = UnetEncodeLayer(kernel_shape, filters)\n",
        "\n",
        "        # block2 encoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) / 2; ex. (32, 32, filters * 2)\n",
        "        self.block2_encoder = UnetEncodeLayer(kernel_shape, filters * 2)\n",
        "\n",
        "        # block 3 encoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) / 2; ex. (16, 16, filters * 4)\n",
        "        self.block3_encoder = UnetEncodeLayer(kernel_shape, filters * 4)\n",
        "\n",
        "        # block 4 encoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) / 2; ex. (8, 8, filters * 8)\n",
        "        self.block4_encoder = UnetEncodeLayer(kernel_shape, filters * 8)\n",
        "\n",
        "        # block middle\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape); ex. (8, 8, filters * 16)\n",
        "        self.middle_block = UnetMiddleLayer(kernel_shape, filters * 16)\n",
        "\n",
        "        # block 4 decoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) * 2; ex. (16, 16, filters * 8)\n",
        "        self.block4_decoder = UnetDecodeLayer(kernel_shape, filters * 8)\n",
        "\n",
        "        # block 3 decoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) * 2; ex. (32, 32, filters * 4)\n",
        "        self.block3_decoder = UnetDecodeLayer(kernel_shape, filters * 4)\n",
        "\n",
        "        # block 2 decoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) * 2; ex. (64, 64, filters * 2)\n",
        "        self.block2_decoder = UnetDecodeLayer(kernel_shape, filters * 2)\n",
        "\n",
        "        # block 1 decoder\n",
        "        # input_shape = output_shape\n",
        "        # output_shape = (input_shape) * 2; ex. (128, 128, filters)\n",
        "        self.block1_decoder = UnetDecodeLayer(kernel_shape, filters)\n",
        "\n",
        "        self.out_layer = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        block1_en_out, block1_en_out_pool = self.block1_encoder(inputs)\n",
        "        block2_en_out, block2_en_out_pool = self.block2_encoder(block1_en_out_pool)\n",
        "        block3_en_out, block3_en_out_pool = self.block3_encoder(block2_en_out_pool)\n",
        "        block4_en_out, block4_en_out_pool = self.block4_encoder(block3_en_out_pool)\n",
        "\n",
        "        middle_out = self.middle_block(block4_en_out_pool)\n",
        "\n",
        "        block4_de_out = self.block4_decoder(middle_out, block4_en_out)\n",
        "        block3_de_out = self.block3_decoder(block4_de_out, block3_en_out)\n",
        "        block2_de_out = self.block2_decoder(block3_de_out, block2_en_out)\n",
        "        block1_de_out = self.block1_decoder(block2_de_out, block1_en_out)\n",
        "        return self.out_layer(block1_de_out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QfrhswIHlA4",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5238f292-e02d-46fa-9a68-38995dc6635b",
        "id": "DqNJ5I0Z6OGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "def build_model(input_layer, start_neurons):\n",
        "    # 128 -> 64\n",
        "    conv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_layer)\n",
        "    conv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(conv1)\n",
        "    pool1 = tf.keras.layers.MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = tf.keras.layers.Dropout(0.25)(pool1)\n",
        "\n",
        "    # 64 -> 32\n",
        "    conv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.01))(pool1)\n",
        "    conv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.01))(conv2)\n",
        "    pool2 = tf.keras.layers.MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = tf.keras.layers.Dropout(0.5)(pool2)\n",
        "\n",
        "    # 32 -> 16\n",
        "    conv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001))(pool2)\n",
        "    conv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001))(conv3)\n",
        "    pool3 = tf.keras.layers.MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = tf.keras.layers.Dropout(0.5)(pool3)\n",
        "\n",
        "    # 16 -> 8\n",
        "    conv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(pool3)\n",
        "    conv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(conv4)\n",
        "    pool4 = tf.keras.layers.MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = tf.keras.layers.Dropout(0.5)(pool4)\n",
        "\n",
        "    # Middle\n",
        "    convm = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(pool4)\n",
        "    convm = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(convm)\n",
        "\n",
        "    # 8 -> 16\n",
        "    deconv4 = tf.keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv4 = tf.keras.layers.concatenate([deconv4, conv4])\n",
        "    uconv4 = tf.keras.layers.Dropout(0.5)(uconv4)\n",
        "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv4)\n",
        "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv4)\n",
        "\n",
        "    # 16 -> 32\n",
        "    deconv3 = tf.keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    uconv3 = tf.keras.layers.concatenate([deconv3, conv3])\n",
        "    uconv3 = tf.keras.layers.Dropout(0.5)(uconv3)\n",
        "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv3)\n",
        "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv3)\n",
        "\n",
        "    # 32 -> 64\n",
        "    deconv2 = tf.keras.layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = tf.keras.layers.concatenate([deconv2, conv2])\n",
        "    uconv2 = tf.keras.layers.Dropout(0.5)(uconv2)\n",
        "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv2)\n",
        "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv2)\n",
        "\n",
        "    # 64 -> 128\n",
        "    deconv1 = tf.keras.layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = tf.keras.layers.concatenate([deconv1, conv1])\n",
        "    uconv1 = tf.keras.layers.Dropout(0.5)(uconv1)\n",
        "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv1)\n",
        "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\",  kernel_regularizer=tf.keras.regularizers.l2(0.001))(uconv1)\n",
        "\n",
        "    #uconv1 = Dropout(0.5)(uconv1)\n",
        "    output_layer = tf.keras.layers.Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "    \n",
        "    return output_layer\n",
        "\n",
        "input_layer = tf.keras.layers.Input((128, 128, 1))\n",
        "output_layer = build_model(input_layer, 16)\n",
        "model = tf.keras.models.Model(input_layer, output_layer)\n",
        "\n",
        "model.compile(loss=dice_loss, optimizer=\"adam\", metrics=[\"accuracy\", dice_coef])\n",
        "\n",
        "ds_train = create_data_set_from_generator(get_train_generator('drive/My Drive/Colab Notebooks/train', mask_dir='masks', img_dir='images'),\n",
        "                                          _types=(tf.float64, tf.float64),\n",
        "                                          _shapes=(tf.TensorShape([128, 128, 1]), tf.TensorShape([128, 128, 1])))\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
        "train_ds = train_ds.batch(32)\n",
        "model.fit(train_ds, epochs = 30, validation_data=valid_ds,\n",
        "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 14:23:49.954592 140305021880192 training_utils.py:1300] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-710f20608beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m model.fit(train_ds, epochs = 30, validation_data=valid_ds,\n\u001b[0;32m---> 78\u001b[0;31m                     callbacks=[early_stopping, model_checkpoint, reduce_lr])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [32,32,128,128,1] and element 3 had shape [4,32,128,128,1]. [Op:IteratorGetNextSync]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsM1GZLsIg7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}